{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOgFdsF/wDMhkGUVSPtJl8o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#connect to google drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ab503ipe5nYz","executionInfo":{"status":"ok","timestamp":1720284656678,"user_tz":-360,"elapsed":27777,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"b1b58bda-7e05-4b0e-a880-f45d5e2d94f6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"dbRTCkzP5iXI","executionInfo":{"status":"ok","timestamp":1720284661480,"user_tz":-360,"elapsed":2232,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}}},"outputs":[],"source":["import numpy as np\n","# Load the data from Google Drive\n","y = np.load('/content/gdrive/MyDrive/ECG/arr2D_AF&SR_label.npy')\n","X = np.load('/content/gdrive/MyDrive/ECG/items_AF&SR.npy')"]},{"cell_type":"code","source":["import numpy as np\n","\n","# Assuming arr is your (6428, 5000, 12) shaped array\n","arr = X\n","# Indices to remove from the third dimension\n","indices_to_remove = [2]  # 1st, 3rd, 7th, 8th positions\n","\n","# Remove the specified positions from the third dimension\n","arr = np.delete(arr, indices_to_remove, axis=2)\n","print(arr.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ciFWESDY5raC","executionInfo":{"status":"ok","timestamp":1720284663096,"user_tz":-360,"elapsed":3,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"651ca346-2047-464e-de83-a39c21526275"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(3587, 1000, 2)\n"]}]},{"cell_type":"code","source":["m= X[2]\n","m"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RzbILLowhhB","executionInfo":{"status":"ok","timestamp":1720285207571,"user_tz":-360,"elapsed":416,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"e97cbf30-c261-48e6-e0b6-32669a8ebaa8"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.47 , -0.43 , -0.72 ],\n","       [-0.47 , -0.43 , -0.72 ],\n","       [-0.47 , -0.43 , -0.72 ],\n","       ...,\n","       [-0.064,  0.111,  0.471],\n","       [-0.075,  0.11 ,  0.467],\n","       [-0.081,  0.11 ,  0.458]])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":[],"metadata":{"id":"H4LT4-KUxKux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X.shape)\n","print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hAzUD0J5xlK","executionInfo":{"status":"ok","timestamp":1720249591395,"user_tz":-360,"elapsed":3,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"39c907b3-07e5-489c-f027-88a702a042d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(3587, 1000, 3)\n","[[[ 0.135 -0.125 -0.08 ]\n","  [ 0.135 -0.125 -0.08 ]\n","  [ 0.135 -0.125 -0.08 ]\n","  ...\n","  [-0.125 -0.066 -0.07 ]\n","  [-0.126 -0.063 -0.07 ]\n","  [-0.124 -0.06  -0.07 ]]\n","\n"," [[-0.13  -0.045 -0.03 ]\n","  [-0.13  -0.045 -0.03 ]\n","  [-0.13  -0.045 -0.03 ]\n","  ...\n","  [ 0.003  0.027 -0.02 ]\n","  [ 0.005  0.025 -0.018]\n","  [ 0.005  0.024 -0.015]]\n","\n"," [[-0.47  -0.43  -0.72 ]\n","  [-0.47  -0.43  -0.72 ]\n","  [-0.47  -0.43  -0.72 ]\n","  ...\n","  [-0.064  0.111  0.471]\n","  [-0.075  0.11   0.467]\n","  [-0.081  0.11   0.458]]\n","\n"," ...\n","\n"," [[ 0.025 -0.065  0.06 ]\n","  [ 0.025 -0.065  0.06 ]\n","  [ 0.025 -0.065  0.06 ]\n","  ...\n","  [-0.012 -0.035 -0.018]\n","  [-0.018 -0.006 -0.016]\n","  [-0.02   0.013 -0.021]]\n","\n"," [[ 0.15   0.15   0.02 ]\n","  [ 0.15   0.15   0.02 ]\n","  [ 0.15   0.15   0.02 ]\n","  ...\n","  [ 0.121  0.05   0.063]\n","  [ 0.146  0.049  0.067]\n","  [ 0.166  0.052  0.071]]\n","\n"," [[ 0.015  0.095 -0.005]\n","  [ 0.015  0.095 -0.005]\n","  [ 0.015  0.095 -0.005]\n","  ...\n","  [-0.102  0.113 -0.13 ]\n","  [-0.099  0.124 -0.129]\n","  [-0.1    0.125 -0.124]]]\n"]}]},{"cell_type":"code","source":["# Preprocessing\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n","\n","print(X_scaled)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JpiwfED51Ca","executionInfo":{"status":"ok","timestamp":1720284704257,"user_tz":-360,"elapsed":1632,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"cd70b320-16ba-4c1f-b33f-9a87fcfa80c8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[ 0.80705828 -0.4588596  -0.25228113]\n","  [ 0.80705828 -0.4588596  -0.25228113]\n","  [ 0.80705828 -0.4588596  -0.25228113]\n","  ...\n","  [-0.71186622 -0.24757386 -0.22215566]\n","  [-0.71770824 -0.23683052 -0.22215566]\n","  [-0.7060242  -0.22608717 -0.22215566]]\n","\n"," [[-0.7410763  -0.17237046 -0.10165378]\n","  [-0.7410763  -0.17237046 -0.10165378]\n","  [-0.7410763  -0.17237046 -0.10165378]\n","  ...\n","  [ 0.035912    0.08546976 -0.07152831]\n","  [ 0.04759603  0.07830753 -0.06550321]\n","  [ 0.04759603  0.07472642 -0.05646557]]\n","\n"," [[-2.72736219 -1.55109943 -2.18031125]\n","  [-2.72736219 -1.55109943 -2.18031125]\n","  [-2.72736219 -1.55109943 -2.18031125]\n","  ...\n","  [-0.35550316  0.38628336  1.4076323 ]\n","  [-0.41976535  0.38270224  1.39558212]\n","  [-0.45481746  0.38270224  1.36846919]]\n","\n"," ...\n","\n"," [[ 0.16443638 -0.24399274  0.16947546]\n","  [ 0.16443638 -0.24399274  0.16947546]\n","  [ 0.16443638 -0.24399274  0.16947546]\n","  ...\n","  [-0.05171826 -0.13655932 -0.06550321]\n","  [-0.08677037 -0.03270701 -0.05947812]\n","  [-0.0984544   0.03533416 -0.07454085]]\n","\n"," [[ 0.89468854  0.52594681  0.04897358]\n","  [ 0.89468854  0.52594681  0.04897358]\n","  [ 0.89468854  0.52594681  0.04897358]\n","  ...\n","  [ 0.72527004  0.16783539  0.1785131 ]\n","  [ 0.87132047  0.16425428  0.19056329]\n","  [ 0.98816082  0.17499762  0.20261348]]\n","\n"," [[ 0.10601621  0.32898553 -0.0263401 ]\n","  [ 0.10601621  0.32898553 -0.0263401 ]\n","  [ 0.10601621  0.32898553 -0.0263401 ]\n","  ...\n","  [-0.57749982  0.39344559 -0.40290848]\n","  [-0.55997377  0.43283784 -0.39989594]\n","  [-0.56581579  0.43641896 -0.3848332 ]]]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Assuming X and Y are your arrays\n","X_s = X_scaled\n","Y_s = y\n","# Generate indices for splitting\n","indices = np.arange(len(Y_s))\n","\n","# Split the indices into train and test sets\n","test_indices = indices[::5]  # Every fifth index\n","train_indices = np.setdiff1d(indices, test_indices)\n","\n","# Split X and Y using the generated indices\n","X_tr = X_s[train_indices]\n","Y_tr = Y_s[train_indices]\n","\n","X_ts = X_s[test_indices]\n","Y_ts = Y_s[test_indices]\n","\n","# Check the shapes\n","print(\"X_train shape:\", X_tr.shape)\n","print(\"Y_train shape:\", Y_tr.shape)\n","print(\"X_test shape:\", X_ts.shape)\n","print(\"Y_test shape:\", Y_ts.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nInk5JDP55ty","executionInfo":{"status":"ok","timestamp":1720284715022,"user_tz":-360,"elapsed":433,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"36d9f61e-b1be-4c3b-bf61-dfe3565ac900"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (2869, 1000, 3)\n","Y_train shape: (2869, 1)\n","X_test shape: (718, 1000, 3)\n","Y_test shape: (718, 1)\n"]}]},{"cell_type":"markdown","source":["# **Teacher Model**"],"metadata":{"id":"PpnEVCFbg-qN"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Bidirectional, Conv1D, MaxPooling1D\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","# Define model parameters\n","num_classes = 2\n","input_shape = (1000, 3)  # assuming 1000 time steps and 3 features\n","\n","# Define LSTM-based teacher model architecture\n","def teacher_model(input_shape, num_classes):\n","    model = Sequential([\n","        Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape),\n","        MaxPooling1D(pool_size=2),\n","        Conv1D(128, kernel_size=3, activation='relu'),\n","        MaxPooling1D(pool_size=2),\n","        Conv1D(256, kernel_size=3, activation='relu'),\n","        MaxPooling1D(pool_size=2),\n","        Conv1D(512, kernel_size=3, activation='relu'),\n","        MaxPooling1D(pool_size=2),\n","        Conv1D(1024, kernel_size=3, activation='relu'),\n","        MaxPooling1D(pool_size=2),\n","        Conv1D(2048, kernel_size=3, activation='relu'),\n","        MaxPooling1D(pool_size=2),\n","        Bidirectional(LSTM(128, return_sequences=True)),\n","        Bidirectional(LSTM(64)),\n","        Dense(128, activation='relu'),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    return model\n","\n","# Instantiate the model\n","teacher_model = teacher_model(input_shape, num_classes)\n","\n","# Compile the model\n","teacher_model.compile(optimizer='adam',\n","                      loss='sparse_categorical_crossentropy',\n","                      metrics=['accuracy'])\n","\n","# Print model summary\n","teacher_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RMS7E6mTKGXP","executionInfo":{"status":"ok","timestamp":1720284725986,"user_tz":-360,"elapsed":5970,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"0ee4511f-e42e-4267-9fce-6c015c4df818"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 998, 64)           640       \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 499, 64)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 497, 128)          24704     \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 248, 128)          0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 246, 256)          98560     \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 123, 256)          0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 121, 512)          393728    \n","                                                                 \n"," max_pooling1d_3 (MaxPoolin  (None, 60, 512)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_4 (Conv1D)           (None, 58, 1024)          1573888   \n","                                                                 \n"," max_pooling1d_4 (MaxPoolin  (None, 29, 1024)          0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_5 (Conv1D)           (None, 27, 2048)          6293504   \n","                                                                 \n"," max_pooling1d_5 (MaxPoolin  (None, 13, 2048)          0         \n"," g1D)                                                            \n","                                                                 \n"," bidirectional (Bidirection  (None, 13, 256)           2229248   \n"," al)                                                             \n","                                                                 \n"," bidirectional_1 (Bidirecti  (None, 128)               164352    \n"," onal)                                                           \n","                                                                 \n"," dense (Dense)               (None, 128)               16512     \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 10795394 (41.18 MB)\n","Trainable params: 10795394 (41.18 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# **Train Teacher (individual, no KD)**"],"metadata":{"id":"1XL1-sqthpeW"}},{"cell_type":"code","source":["# Define callbacks\n","checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, mode='max', restore_best_weights=True)\n","\n","# Train the model\n","teacher_model.fit(X_tr, Y_tr, epochs=50, batch_size=32, validation_split=0.3, callbacks=[checkpoint, early_stopping])\n","\n","# Load the best model\n","teacher_model.load_weights('best_model.h5')\n","\n","# Evaluate the model on test data\n","loss, accuracy = teacher_model.evaluate(X_ts, Y_ts)\n","print(\"Test Loss:\", loss)\n","print(\"Test Accuracy:\", accuracy)"],"metadata":{"id":"JHja75iOhzdV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720167964356,"user_tz":-360,"elapsed":139187,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"404ccae6-a759-44db-9010-100c8be9f9f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","63/63 [==============================] - 3s 50ms/step - loss: 0.0425 - accuracy: 0.9856 - val_loss: 0.3241 - val_accuracy: 0.9164\n","Epoch 2/50\n","63/63 [==============================] - 3s 50ms/step - loss: 0.0788 - accuracy: 0.9671 - val_loss: 0.2675 - val_accuracy: 0.9187\n","Epoch 3/50\n","63/63 [==============================] - 3s 44ms/step - loss: 0.0684 - accuracy: 0.9741 - val_loss: 0.2409 - val_accuracy: 0.9152\n","Epoch 4/50\n","63/63 [==============================] - 3s 47ms/step - loss: 0.0294 - accuracy: 0.9875 - val_loss: 0.2850 - val_accuracy: 0.9268\n","Epoch 5/50\n","63/63 [==============================] - 3s 42ms/step - loss: 0.0568 - accuracy: 0.9791 - val_loss: 0.3114 - val_accuracy: 0.9036\n","Epoch 6/50\n","63/63 [==============================] - 3s 46ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.2959 - val_accuracy: 0.9245\n","Epoch 7/50\n","63/63 [==============================] - 3s 51ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.2951 - val_accuracy: 0.9315\n","Epoch 8/50\n","63/63 [==============================] - 3s 43ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.3351 - val_accuracy: 0.9199\n","Epoch 9/50\n","63/63 [==============================] - 3s 42ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9210\n","Epoch 10/50\n","63/63 [==============================] - 3s 42ms/step - loss: 2.6138e-04 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9210\n","Epoch 11/50\n","63/63 [==============================] - 3s 42ms/step - loss: 1.1437e-04 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.9292\n","Epoch 12/50\n","63/63 [==============================] - 3s 44ms/step - loss: 6.6415e-05 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.9257\n","Epoch 13/50\n","63/63 [==============================] - 3s 43ms/step - loss: 5.6819e-05 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.9245\n","Epoch 14/50\n","63/63 [==============================] - 3s 42ms/step - loss: 4.6158e-05 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.9303\n","Epoch 15/50\n","63/63 [==============================] - 3s 47ms/step - loss: 2.7751e-05 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9315\n","Epoch 16/50\n","63/63 [==============================] - 3s 48ms/step - loss: 1.9963e-05 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.9338\n","Epoch 17/50\n","63/63 [==============================] - 3s 51ms/step - loss: 1.5440e-05 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.9384\n","Epoch 18/50\n","63/63 [==============================] - 3s 42ms/step - loss: 1.2691e-05 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.9384\n","Epoch 19/50\n","63/63 [==============================] - 3s 42ms/step - loss: 1.0542e-05 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.9384\n","Epoch 20/50\n","63/63 [==============================] - 3s 41ms/step - loss: 9.0927e-06 - accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.9384\n","Epoch 21/50\n","63/63 [==============================] - 3s 42ms/step - loss: 7.8880e-06 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.9384\n","Epoch 22/50\n","63/63 [==============================] - 3s 49ms/step - loss: 6.9654e-06 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9384\n","Epoch 23/50\n","63/63 [==============================] - 3s 41ms/step - loss: 6.1464e-06 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9384\n","Epoch 24/50\n","63/63 [==============================] - 3s 41ms/step - loss: 5.4514e-06 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.9384\n","Epoch 25/50\n","63/63 [==============================] - 3s 47ms/step - loss: 4.7416e-06 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.9396\n","Epoch 26/50\n","63/63 [==============================] - 3s 47ms/step - loss: 4.1842e-06 - accuracy: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.9384\n","Epoch 27/50\n","63/63 [==============================] - 3s 44ms/step - loss: 3.8679e-06 - accuracy: 1.0000 - val_loss: 0.5017 - val_accuracy: 0.9396\n","Epoch 28/50\n","63/63 [==============================] - 3s 41ms/step - loss: 3.5676e-06 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.9396\n","Epoch 29/50\n","63/63 [==============================] - 3s 41ms/step - loss: 2.9782e-06 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.9396\n","Epoch 30/50\n","63/63 [==============================] - 3s 41ms/step - loss: 2.5870e-06 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.9396\n","Epoch 31/50\n","63/63 [==============================] - 3s 47ms/step - loss: 2.2652e-06 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.9373\n","Epoch 32/50\n","63/63 [==============================] - 3s 44ms/step - loss: 2.0203e-06 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9373\n","Epoch 33/50\n","63/63 [==============================] - 3s 41ms/step - loss: 1.8225e-06 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.9396\n","Epoch 34/50\n","63/63 [==============================] - 3s 47ms/step - loss: 1.6421e-06 - accuracy: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.9408\n","Epoch 35/50\n","63/63 [==============================] - 3s 42ms/step - loss: 1.5171e-06 - accuracy: 1.0000 - val_loss: 0.5246 - val_accuracy: 0.9373\n","Epoch 36/50\n","63/63 [==============================] - 3s 43ms/step - loss: 1.4078e-06 - accuracy: 1.0000 - val_loss: 0.5211 - val_accuracy: 0.9361\n","Epoch 37/50\n","63/63 [==============================] - 3s 43ms/step - loss: 1.2650e-06 - accuracy: 1.0000 - val_loss: 0.5241 - val_accuracy: 0.9373\n","Epoch 38/50\n","63/63 [==============================] - 3s 41ms/step - loss: 1.1674e-06 - accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.9373\n","Epoch 39/50\n","63/63 [==============================] - 3s 42ms/step - loss: 1.0717e-06 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.9384\n","Epoch 40/50\n","63/63 [==============================] - 3s 42ms/step - loss: 9.9676e-07 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.9384\n","Epoch 41/50\n","63/63 [==============================] - 3s 48ms/step - loss: 9.1994e-07 - accuracy: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.9384\n","Epoch 42/50\n","63/63 [==============================] - 3s 43ms/step - loss: 8.5078e-07 - accuracy: 1.0000 - val_loss: 0.5355 - val_accuracy: 0.9384\n","Epoch 43/50\n","63/63 [==============================] - 3s 42ms/step - loss: 8.0448e-07 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.9384\n","Epoch 44/50\n","63/63 [==============================] - 3s 42ms/step - loss: 7.5241e-07 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.9384\n","Epoch 45/50\n","63/63 [==============================] - 3s 42ms/step - loss: 7.1667e-07 - accuracy: 1.0000 - val_loss: 0.5480 - val_accuracy: 0.9396\n","Epoch 46/50\n","63/63 [==============================] - 3s 44ms/step - loss: 6.7251e-07 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.9384\n","Epoch 47/50\n","63/63 [==============================] - 3s 48ms/step - loss: 6.4164e-07 - accuracy: 1.0000 - val_loss: 0.5482 - val_accuracy: 0.9384\n","Epoch 48/50\n","63/63 [==============================] - 3s 41ms/step - loss: 6.0020e-07 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.9396\n","Epoch 49/50\n","63/63 [==============================] - 3s 42ms/step - loss: 5.7301e-07 - accuracy: 1.0000 - val_loss: 0.5540 - val_accuracy: 0.9396\n","Epoch 50/50\n","63/63 [==============================] - 3s 42ms/step - loss: 5.4344e-07 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.9408\n","23/23 [==============================] - 0s 12ms/step - loss: 0.7022 - accuracy: 0.9234\n","Test Loss: 0.7021604776382446\n","Test Accuracy: 0.9233983159065247\n"]}]},{"cell_type":"markdown","source":["# **Student Model**"],"metadata":{"id":"UqBJ8spNh4fG"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","# Define model parameters\n","num_classes = 2\n","input_shape = (1000, 3)  # assuming 1000 time steps and 3 features\n","\n","def student_model(input_shape, num_classes):\n","    model = Sequential([\n","        Conv1D(16, kernel_size=3, activation='relu', input_shape=input_shape),\n","        MaxPooling1D(pool_size=2),\n","        Conv1D(32, kernel_size=3, activation='relu'),\n","        MaxPooling1D(pool_size=2),\n","        Dropout(0.3),\n","        LSTM(16, return_sequences=True),\n","        LSTM(8),\n","        Dropout(0.3),\n","        Dense(16, activation='relu'),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    return model\n","\n","# Instantiate and compile the student model\n","student_model = student_model(input_shape, num_classes)\n","student_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","student_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OxTfAs4txmnH","outputId":"c6f8c172-5608-4db8-ecef-0108a4d637a9","executionInfo":{"status":"ok","timestamp":1720284741282,"user_tz":-360,"elapsed":1350,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d_6 (Conv1D)           (None, 998, 16)           160       \n","                                                                 \n"," max_pooling1d_6 (MaxPoolin  (None, 499, 16)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_7 (Conv1D)           (None, 497, 32)           1568      \n","                                                                 \n"," max_pooling1d_7 (MaxPoolin  (None, 248, 32)           0         \n"," g1D)                                                            \n","                                                                 \n"," dropout (Dropout)           (None, 248, 32)           0         \n","                                                                 \n"," lstm_2 (LSTM)               (None, 248, 16)           3136      \n","                                                                 \n"," lstm_3 (LSTM)               (None, 8)                 800       \n","                                                                 \n"," dropout_1 (Dropout)         (None, 8)                 0         \n","                                                                 \n"," dense_2 (Dense)             (None, 16)                144       \n","                                                                 \n"," dense_3 (Dense)             (None, 2)                 34        \n","                                                                 \n","=================================================================\n","Total params: 5842 (22.82 KB)\n","Trainable params: 5842 (22.82 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# **Train Student (Individual, no KD)**"],"metadata":{"id":"FLkXsEyohQLG"}},{"cell_type":"code","source":["# Define callbacks\n","checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, mode='max', restore_best_weights=True)\n","\n","# Train the model\n","student_model.fit(X_tr, Y_tr, epochs=10, batch_size=32, validation_split=0.3, callbacks=[checkpoint, early_stopping])\n","\n","# Load the best model\n","student_model.load_weights('best_model.h5')\n","\n","# Evaluate the model on test data\n","loss, accuracy = student_model.evaluate(X_ts, Y_ts)\n","print(\"Test Loss:\", loss)\n","print(\"Test Accuracy:\", accuracy)"],"metadata":{"id":"Ecz0yrtThJav","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720284797316,"user_tz":-360,"elapsed":45871,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"c912908f-6d62-46a5-c281-b1792c3e2f47"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","63/63 [==============================] - 13s 73ms/step - loss: 0.6892 - accuracy: 0.5393 - val_loss: 0.6824 - val_accuracy: 0.5645\n","Epoch 2/10\n"," 1/63 [..............................] - ETA: 2s - loss: 0.6724 - accuracy: 0.5625"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["63/63 [==============================] - 3s 43ms/step - loss: 0.6722 - accuracy: 0.5832 - val_loss: 0.6516 - val_accuracy: 0.6109\n","Epoch 3/10\n","63/63 [==============================] - 4s 57ms/step - loss: 0.6529 - accuracy: 0.6180 - val_loss: 0.6562 - val_accuracy: 0.5947\n","Epoch 4/10\n","63/63 [==============================] - 3s 45ms/step - loss: 0.6455 - accuracy: 0.6320 - val_loss: 0.6235 - val_accuracy: 0.6609\n","Epoch 5/10\n","63/63 [==============================] - 1s 23ms/step - loss: 0.6455 - accuracy: 0.6429 - val_loss: 0.6362 - val_accuracy: 0.6423\n","Epoch 6/10\n","63/63 [==============================] - 1s 23ms/step - loss: 0.6409 - accuracy: 0.6599 - val_loss: 0.6266 - val_accuracy: 0.6736\n","Epoch 7/10\n","63/63 [==============================] - 1s 20ms/step - loss: 0.6953 - accuracy: 0.5309 - val_loss: 0.6864 - val_accuracy: 0.5598\n","Epoch 8/10\n","63/63 [==============================] - 1s 20ms/step - loss: 0.6855 - accuracy: 0.5558 - val_loss: 0.6828 - val_accuracy: 0.5598\n","Epoch 9/10\n","63/63 [==============================] - 1s 20ms/step - loss: 0.6798 - accuracy: 0.5603 - val_loss: 0.6704 - val_accuracy: 0.5761\n","Epoch 10/10\n","63/63 [==============================] - 1s 23ms/step - loss: 0.6686 - accuracy: 0.5926 - val_loss: 0.7139 - val_accuracy: 0.5656\n","23/23 [==============================] - 0s 15ms/step - loss: 0.6322 - accuracy: 0.6560\n","Test Loss: 0.6322410702705383\n","Test Accuracy: 0.655988872051239\n"]}]},{"cell_type":"code","source":["student_model.save('model.h5')\n","from google.colab import files\n","\n","# Download the saved model file\n","files.download('model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"hgLbfQsc5aXr","executionInfo":{"status":"ok","timestamp":1720284813708,"user_tz":-360,"elapsed":420,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"cba2a2c6-2890-451b-f3ec-4c223ffe40a3"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a55ad692-2ce7-4e33-901d-4adb531dd9ce\", \"model.h5\", 139712)"]},"metadata":{}}]},{"cell_type":"markdown","source":["# **KD Training**"],"metadata":{"id":"qFbyJRQaiBoe"}},{"cell_type":"code","source":["import tensorflow as tf\n","from keras import Model\n","from keras.losses import KLDivergence\n","\n","# Custom training step for knowledge distillation\n","class DistillationModel(Model):\n","    def __init__(self, student, teacher, alpha=0.1, temperature=3):\n","        super(DistillationModel, self).__init__()\n","        self.student = student\n","        self.teacher = teacher\n","        self.alpha = alpha\n","        self.temperature = temperature\n","        self.student_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","        self.distillation_loss_fn = KLDivergence()\n","        self.best_accuracy = 0.0\n","        self.best_student_weights = None\n","\n","    def compile(self, optimizer, metrics):\n","        super(DistillationModel, self).compile(optimizer=optimizer, metrics=metrics)\n","        self.student_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","        self.distillation_loss_fn = KLDivergence()\n","\n","    def train_step(self, data):\n","        x, y = data\n","        teacher_predictions = self.teacher(x, training=False)\n","\n","        with tf.GradientTape() as tape:\n","            student_predictions = self.student(x, training=True)\n","            student_loss = self.student_loss_fn(y, student_predictions)\n","            distillation_loss = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions / self.temperature, axis=1)\n","            )\n","            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss * (self.temperature ** 2)\n","\n","        gradients = tape.gradient(loss, self.student.trainable_variables)\n","        self.optimizer.apply_gradients(zip(gradients, self.student.trainable_variables))\n","\n","        self.compiled_metrics.update_state(y, student_predictions)\n","        return {m.name: m.result() for m in self.metrics}\n","\n","    def test_step(self, data):\n","        x, y = data\n","        y_pred = self.student(x, training=False)\n","        loss = self.student_loss_fn(y, y_pred)\n","\n","        self.compiled_metrics.update_state(y, y_pred)\n","        return {m.name: m.result() for m in self.metrics}\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        current_val_accuracy = logs.get('val_accuracy')\n","        if current_val_accuracy is not None and current_val_accuracy > self.best_accuracy:\n","            self.best_accuracy = current_val_accuracy\n","            self.best_student_weights = self.student.get_weights()\n","\n","    def get_best_accuracy(self):\n","        return self.best_accuracy\n","\n","    def get_best_student_weights(self):\n","        return self.best_student_weights\n","\n","# Instantiate and compile the distillation model\n","distillation_model = DistillationModel(student=student_model, teacher=teacher_model, alpha=0.1, temperature=2)\n","distillation_model.compile(optimizer='adam', metrics=['accuracy'])\n","\n","# Train the student model with knowledge distillation\n","history = distillation_model.fit(X_tr, Y_tr, epochs=50, batch_size=32, validation_split=0.2)\n","\n","# Retrieve the best validation accuracy and corresponding student weights\n","best_accuracy = distillation_model.get_best_accuracy()\n","best_student_weights = distillation_model.get_best_student_weights()\n","\n","# Set the best weights to the student model for final evaluation\n","if best_student_weights is not None:\n","    student_model.set_weights(best_student_weights)\n","\n","# Evaluate on test data\n","test_loss, test_accuracy = student_model.evaluate(X_ts, Y_ts)\n","print(\"Test Accuracy:\", test_accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJWdWk2g9nQn","outputId":"a49e671a-3357-4c40-9310-7e625c52f45e","executionInfo":{"status":"ok","timestamp":1720171955157,"user_tz":-360,"elapsed":119312,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","72/72 [==============================] - 10s 40ms/step - accuracy: 0.5621 - val_accuracy: 0.5645\n","Epoch 2/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.5908 - val_accuracy: 0.5993\n","Epoch 3/50\n","72/72 [==============================] - 2s 27ms/step - accuracy: 0.6148 - val_accuracy: 0.6010\n","Epoch 4/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.6349 - val_accuracy: 0.6551\n","Epoch 5/50\n","72/72 [==============================] - 2s 29ms/step - accuracy: 0.6340 - val_accuracy: 0.6672\n","Epoch 6/50\n","72/72 [==============================] - 2s 34ms/step - accuracy: 0.6471 - val_accuracy: 0.6760\n","Epoch 7/50\n","72/72 [==============================] - 2s 31ms/step - accuracy: 0.6658 - val_accuracy: 0.6585\n","Epoch 8/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.6693 - val_accuracy: 0.6864\n","Epoch 9/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.6758 - val_accuracy: 0.6707\n","Epoch 10/50\n","72/72 [==============================] - 2s 27ms/step - accuracy: 0.6732 - val_accuracy: 0.7056\n","Epoch 11/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.6806 - val_accuracy: 0.7091\n","Epoch 12/50\n","72/72 [==============================] - 2s 33ms/step - accuracy: 0.6967 - val_accuracy: 0.7056\n","Epoch 13/50\n","72/72 [==============================] - 2s 33ms/step - accuracy: 0.6876 - val_accuracy: 0.7038\n","Epoch 14/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.6959 - val_accuracy: 0.7213\n","Epoch 15/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.7159 - val_accuracy: 0.7195\n","Epoch 16/50\n","72/72 [==============================] - 2s 27ms/step - accuracy: 0.7120 - val_accuracy: 0.7265\n","Epoch 17/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.7351 - val_accuracy: 0.7404\n","Epoch 18/50\n","72/72 [==============================] - 2s 29ms/step - accuracy: 0.7399 - val_accuracy: 0.7404\n","Epoch 19/50\n","72/72 [==============================] - 2s 34ms/step - accuracy: 0.7342 - val_accuracy: 0.7213\n","Epoch 20/50\n","72/72 [==============================] - 2s 30ms/step - accuracy: 0.7451 - val_accuracy: 0.7735\n","Epoch 21/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.7525 - val_accuracy: 0.7578\n","Epoch 22/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.7525 - val_accuracy: 0.7631\n","Epoch 23/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.7564 - val_accuracy: 0.7317\n","Epoch 24/50\n","72/72 [==============================] - 2s 27ms/step - accuracy: 0.7516 - val_accuracy: 0.7648\n","Epoch 25/50\n","72/72 [==============================] - 2s 32ms/step - accuracy: 0.7643 - val_accuracy: 0.7718\n","Epoch 26/50\n","72/72 [==============================] - 2s 33ms/step - accuracy: 0.7773 - val_accuracy: 0.7770\n","Epoch 27/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.7747 - val_accuracy: 0.7544\n","Epoch 28/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.7826 - val_accuracy: 0.7648\n","Epoch 29/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.7817 - val_accuracy: 0.7909\n","Epoch 30/50\n","72/72 [==============================] - 2s 27ms/step - accuracy: 0.7908 - val_accuracy: 0.7822\n","Epoch 31/50\n","72/72 [==============================] - 2s 30ms/step - accuracy: 0.7961 - val_accuracy: 0.8188\n","Epoch 32/50\n","72/72 [==============================] - 3s 35ms/step - accuracy: 0.7965 - val_accuracy: 0.8066\n","Epoch 33/50\n","72/72 [==============================] - 3s 45ms/step - accuracy: 0.7586 - val_accuracy: 0.7683\n","Epoch 34/50\n","72/72 [==============================] - 3s 37ms/step - accuracy: 0.7813 - val_accuracy: 0.7857\n","Epoch 35/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.7721 - val_accuracy: 0.7352\n","Epoch 36/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.8013 - val_accuracy: 0.7997\n","Epoch 37/50\n","72/72 [==============================] - 2s 33ms/step - accuracy: 0.8083 - val_accuracy: 0.8345\n","Epoch 38/50\n","72/72 [==============================] - 2s 34ms/step - accuracy: 0.8196 - val_accuracy: 0.8293\n","Epoch 39/50\n","72/72 [==============================] - 2s 31ms/step - accuracy: 0.8240 - val_accuracy: 0.7578\n","Epoch 40/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.8061 - val_accuracy: 0.8223\n","Epoch 41/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.7725 - val_accuracy: 0.7875\n","Epoch 42/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.8065 - val_accuracy: 0.8328\n","Epoch 43/50\n","72/72 [==============================] - 2s 31ms/step - accuracy: 0.8275 - val_accuracy: 0.8293\n","Epoch 44/50\n","72/72 [==============================] - 3s 35ms/step - accuracy: 0.8170 - val_accuracy: 0.7892\n","Epoch 45/50\n","72/72 [==============================] - 2s 29ms/step - accuracy: 0.7826 - val_accuracy: 0.7700\n","Epoch 46/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.8118 - val_accuracy: 0.8328\n","Epoch 47/50\n","72/72 [==============================] - 2s 29ms/step - accuracy: 0.8349 - val_accuracy: 0.8066\n","Epoch 48/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.8479 - val_accuracy: 0.8693\n","Epoch 49/50\n","72/72 [==============================] - 2s 28ms/step - accuracy: 0.8505 - val_accuracy: 0.8345\n","Epoch 50/50\n","72/72 [==============================] - 3s 35ms/step - accuracy: 0.8362 - val_accuracy: 0.8293\n","23/23 [==============================] - 2s 12ms/step - loss: 0.5554 - accuracy: 0.8301\n","Test Accuracy: 0.8300835490226746\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from keras import Model\n","from keras.losses import KLDivergence\n","\n","# Custom training step for knowledge distillation\n","class DistillationModel(Model):\n","    def __init__(self, student, teacher, alpha=0.1, temperature=3):\n","        super(DistillationModel, self).__init__()\n","        self.student = student\n","        self.teacher = teacher\n","        self.alpha = alpha\n","        self.temperature = temperature\n","        self.student_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","        self.distillation_loss_fn = KLDivergence()\n","        self.best_accuracy = 0.0\n","        self.best_student_weights = None\n","\n","    def compile(self, optimizer, metrics):\n","        super(DistillationModel, self).compile(optimizer=optimizer, metrics=metrics)\n","        self.student_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","        self.distillation_loss_fn = KLDivergence()\n","\n","    def train_step(self, data):\n","        x, y = data\n","        teacher_predictions = self.teacher(x, training=False)\n","\n","        with tf.GradientTape() as tape:\n","            student_predictions = self.student(x, training=True)\n","            student_loss = self.student_loss_fn(y, student_predictions)\n","            distillation_loss = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions / self.temperature, axis=1)\n","            )\n","            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss * (self.temperature ** 2)\n","\n","        gradients = tape.gradient(loss, self.student.trainable_variables)\n","        self.optimizer.apply_gradients(zip(gradients, self.student.trainable_variables))\n","\n","        self.compiled_metrics.update_state(y, student_predictions)\n","        return {m.name: m.result() for m in self.metrics}\n","\n","    def test_step(self, data):\n","        x, y = data\n","        y_pred = self.student(x, training=False)\n","        loss = self.student_loss_fn(y, y_pred)\n","\n","        self.compiled_metrics.update_state(y, y_pred)\n","        return {m.name: m.result() for m in self.metrics}\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        current_val_accuracy = logs.get('val_accuracy')\n","        if current_val_accuracy is not None and current_val_accuracy > self.best_accuracy:\n","            self.best_accuracy = current_val_accuracy\n","            self.best_student_weights = self.student.get_weights()\n","\n","    def get_best_accuracy(self):\n","        return self.best_accuracy\n","\n","    def get_best_student_weights(self):\n","        return self.best_student_weights\n","\n","# Instantiate and compile the distillation model\n","distillation_model = DistillationModel(student=student_model, teacher=teacher_model, alpha=0.01, temperature=2)\n","distillation_model.compile(optimizer='adam', metrics=['accuracy'])\n","\n","# Train the student model with knowledge distillation\n","history = distillation_model.fit(X_tr, Y_tr, epochs=50, batch_size=32, validation_split=0.2)\n","\n","# Retrieve the best validation accuracy and corresponding student weights\n","best_accuracy = distillation_model.get_best_accuracy()\n","best_student_weights = distillation_model.get_best_student_weights()\n","\n","# Set the best weights to the student model for final evaluation\n","if best_student_weights is not None:\n","    student_model.set_weights(best_student_weights)\n","\n","# Evaluate on test data\n","test_loss, test_accuracy = student_model.evaluate(X_ts, Y_ts)\n","print(\"Test Accuracy:\", test_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TZlycF2tQGhB","executionInfo":{"status":"ok","timestamp":1720174758857,"user_tz":-360,"elapsed":2312418,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"bd34dbdd-a21b-44a6-f1e2-85502da3d7b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","72/72 [==============================] - 54s 645ms/step - accuracy: 0.4954 - val_accuracy: 0.4843\n","Epoch 2/50\n","72/72 [==============================] - 45s 629ms/step - accuracy: 0.4963 - val_accuracy: 0.5592\n","Epoch 3/50\n","72/72 [==============================] - 47s 654ms/step - accuracy: 0.5142 - val_accuracy: 0.5523\n","Epoch 4/50\n","72/72 [==============================] - 46s 635ms/step - accuracy: 0.5325 - val_accuracy: 0.5976\n","Epoch 5/50\n","72/72 [==============================] - 46s 639ms/step - accuracy: 0.5691 - val_accuracy: 0.5540\n","Epoch 6/50\n","72/72 [==============================] - 46s 634ms/step - accuracy: 0.5769 - val_accuracy: 0.5889\n","Epoch 7/50\n","72/72 [==============================] - 45s 629ms/step - accuracy: 0.5965 - val_accuracy: 0.6359\n","Epoch 8/50\n","72/72 [==============================] - 45s 628ms/step - accuracy: 0.5961 - val_accuracy: 0.6254\n","Epoch 9/50\n","72/72 [==============================] - 46s 634ms/step - accuracy: 0.6044 - val_accuracy: 0.6185\n","Epoch 10/50\n","72/72 [==============================] - 45s 632ms/step - accuracy: 0.6170 - val_accuracy: 0.6254\n","Epoch 11/50\n","72/72 [==============================] - 45s 632ms/step - accuracy: 0.6126 - val_accuracy: 0.6533\n","Epoch 12/50\n","72/72 [==============================] - 45s 632ms/step - accuracy: 0.6375 - val_accuracy: 0.6446\n","Epoch 13/50\n","72/72 [==============================] - 45s 628ms/step - accuracy: 0.6331 - val_accuracy: 0.6289\n","Epoch 14/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.6288 - val_accuracy: 0.5470\n","Epoch 15/50\n","72/72 [==============================] - 45s 628ms/step - accuracy: 0.6449 - val_accuracy: 0.6551\n","Epoch 16/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.6497 - val_accuracy: 0.6167\n","Epoch 17/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.6549 - val_accuracy: 0.5819\n","Epoch 18/50\n","72/72 [==============================] - 45s 633ms/step - accuracy: 0.6614 - val_accuracy: 0.6882\n","Epoch 19/50\n","72/72 [==============================] - 45s 632ms/step - accuracy: 0.6723 - val_accuracy: 0.6429\n","Epoch 20/50\n","72/72 [==============================] - 45s 632ms/step - accuracy: 0.6684 - val_accuracy: 0.6916\n","Epoch 21/50\n","72/72 [==============================] - 45s 632ms/step - accuracy: 0.6876 - val_accuracy: 0.6690\n","Epoch 22/50\n","72/72 [==============================] - 45s 632ms/step - accuracy: 0.6915 - val_accuracy: 0.7213\n","Epoch 23/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.7037 - val_accuracy: 0.7038\n","Epoch 24/50\n","72/72 [==============================] - 45s 631ms/step - accuracy: 0.6837 - val_accuracy: 0.6794\n","Epoch 25/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.7041 - val_accuracy: 0.7213\n","Epoch 26/50\n","72/72 [==============================] - 45s 632ms/step - accuracy: 0.7094 - val_accuracy: 0.7422\n","Epoch 27/50\n","72/72 [==============================] - 45s 628ms/step - accuracy: 0.7033 - val_accuracy: 0.7108\n","Epoch 28/50\n","72/72 [==============================] - 45s 633ms/step - accuracy: 0.7115 - val_accuracy: 0.7160\n","Epoch 29/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.6453 - val_accuracy: 0.5662\n","Epoch 30/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.6096 - val_accuracy: 0.6132\n","Epoch 31/50\n","72/72 [==============================] - 45s 629ms/step - accuracy: 0.6980 - val_accuracy: 0.6568\n","Epoch 32/50\n","72/72 [==============================] - 46s 646ms/step - accuracy: 0.6266 - val_accuracy: 0.7509\n","Epoch 33/50\n","72/72 [==============================] - 45s 632ms/step - accuracy: 0.7351 - val_accuracy: 0.7544\n","Epoch 34/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.7403 - val_accuracy: 0.7247\n","Epoch 35/50\n","72/72 [==============================] - 45s 631ms/step - accuracy: 0.7451 - val_accuracy: 0.7300\n","Epoch 36/50\n","72/72 [==============================] - 45s 627ms/step - accuracy: 0.7521 - val_accuracy: 0.7718\n","Epoch 37/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.7364 - val_accuracy: 0.7352\n","Epoch 38/50\n","72/72 [==============================] - 45s 633ms/step - accuracy: 0.5983 - val_accuracy: 0.7038\n","Epoch 39/50\n","72/72 [==============================] - 45s 631ms/step - accuracy: 0.6863 - val_accuracy: 0.7369\n","Epoch 40/50\n","72/72 [==============================] - 45s 631ms/step - accuracy: 0.7285 - val_accuracy: 0.7613\n","Epoch 41/50\n","72/72 [==============================] - 45s 632ms/step - accuracy: 0.7281 - val_accuracy: 0.7613\n","Epoch 42/50\n","72/72 [==============================] - 46s 634ms/step - accuracy: 0.7394 - val_accuracy: 0.7160\n","Epoch 43/50\n","72/72 [==============================] - 45s 631ms/step - accuracy: 0.7586 - val_accuracy: 0.7456\n","Epoch 44/50\n","72/72 [==============================] - 45s 629ms/step - accuracy: 0.7634 - val_accuracy: 0.7962\n","Epoch 45/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.7651 - val_accuracy: 0.7735\n","Epoch 46/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.7752 - val_accuracy: 0.7753\n","Epoch 47/50\n","72/72 [==============================] - 45s 631ms/step - accuracy: 0.7786 - val_accuracy: 0.8188\n","Epoch 48/50\n","72/72 [==============================] - 45s 631ms/step - accuracy: 0.8013 - val_accuracy: 0.8101\n","Epoch 49/50\n","72/72 [==============================] - 45s 632ms/step - accuracy: 0.7983 - val_accuracy: 0.8118\n","Epoch 50/50\n","72/72 [==============================] - 45s 630ms/step - accuracy: 0.8087 - val_accuracy: 0.8328\n","23/23 [==============================] - 2s 36ms/step - loss: 0.6768 - accuracy: 0.8036\n","Test Accuracy: 0.8036211729049683\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","# Assuming you have predictions and true labels from your test set\n","y_pred = student_model.predict(X_ts)\n","y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax probabilities to class labels\n","y_true = np.argmax(Y_ts, axis=1)  # Assuming Y_test is one-hot encoded\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_classes)\n","\n","# Plot confusion matrix as an image\n","plt.figure(figsize=(6, 6))\n","sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False)\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title('Confusion Matrix')\n","plt.savefig('confusion_matrix.png')\n","plt.show()\n","\n","# Compute precision, recall, f1-score\n","print(classification_report(y_true, y_pred_classes))"],"metadata":{"id":"5rYibP1_aVbi","colab":{"base_uri":"https://localhost:8080/","height":862},"executionInfo":{"status":"ok","timestamp":1720171972865,"user_tz":-360,"elapsed":3313,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"9d086ff7-1f05-43c1-960e-c41a4750838d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["23/23 [==============================] - 2s 13ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 600x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.63      0.77       718\n","           1       0.00      0.00      0.00         0\n","\n","    accuracy                           0.63       718\n","   macro avg       0.50      0.32      0.39       718\n","weighted avg       1.00      0.63      0.77       718\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from keras.models import load_model\n","df=pd.read_csv(\"/content/gdrive/MyDrive/ECG/sample_ecg.csv\")\n","array = df.iloc[:, 0].values\n","array_parts = np.array_split(array, 3)\n","filtered_parts = [part[:1000] for part in array_parts]\n","result_array = []\n","for i in range(1000):\n","    result_array.append([part[i] for part in filtered_parts])\n","result_array = np.array(result_array)\n","sample= result_array\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","Sample_scaled = scaler.fit_transform(sample.reshape(-1, sample.shape[-1])).reshape(sample.shape)\n","print(Sample_scaled)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxJQr55XxNKq","executionInfo":{"status":"ok","timestamp":1720284989722,"user_tz":-360,"elapsed":691,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"983bcc25-088f-4f46-e9b5-9351ec7c2e33"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.99749133 -1.55768829 -1.56439326]\n"," [ 0.96832246 -2.11534591 -2.12998041]\n"," [ 0.93681225 -2.46297411 -2.48415649]\n"," ...\n"," [-0.30644964 -0.14833662 -0.16149087]\n"," [-0.29590658 -0.14184632 -0.15546107]\n"," [-0.29149532 -0.13285674 -0.14353196]]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from keras.models import load_model\n","\n","student_model = load_model('/content/gdrive/MyDrive/ECG/student_KD_model.h5')\n","sample = np.array(Sample_scaled)\n","pred = student_model.predict(sample)\n","label = ['Normal SR' if pred == 0 else 'Abnormal AF']\n","print(f\"Prediction for array: {label}\")"],"metadata":{"id":"XlO1B9lJz8Wx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720285570685,"user_tz":-360,"elapsed":448,"user":{"displayName":"Flying fox","userId":"00803030206233269286"}},"outputId":"d218c359-0817-44d2-cec1-0501a709c17e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction for array: Normal SR\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5nacQvEHAoeO"},"execution_count":null,"outputs":[]}]}